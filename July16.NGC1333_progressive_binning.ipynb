{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "a= 64\n",
      "len(bin_arr)= 65600\n",
      "b= 41\n",
      "bin_num= 13\n",
      "f(bin_arr)= [array([  7.42259303e+22,   7.30171752e+22,   7.26586133e+22, ...,\n",
      "         1.83380933e+21,   1.83375679e+21,   1.83333765e+21]), array([  1.83326975e+21,   1.83325930e+21,   1.83313154e+21, ...,\n",
      "         1.03064421e+21,   1.03062694e+21,   1.03062206e+21]), array([  1.03061965e+21,   1.03059606e+21,   1.03059166e+21, ...,\n",
      "         6.15158216e+20,   6.15154201e+20,   6.14973079e+20]), array([  6.14940757e+20,   6.14921393e+20,   6.14896562e+20, ...,\n",
      "         4.72954737e+20,   4.72425565e+20,   4.72396713e+20])]\n",
      "len(f(bin_arr))= 4\n",
      "len(f(bin_arr)[0])= 20800\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 32\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 16\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 8\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 4\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 2\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(x)= 0\n",
      "len(y)= 0\n",
      "a= 64\n",
      "len(bin_arr)= 65600\n",
      "b= 41\n",
      "bin_num= 13\n",
      "f(bin_arr)= [array([  7.42259303e+22,   7.30171752e+22,   7.26586133e+22, ...,\n",
      "         1.83380933e+21,   1.83375679e+21,   1.83333765e+21]), array([  1.83326975e+21,   1.83325930e+21,   1.83313154e+21, ...,\n",
      "         1.03064421e+21,   1.03062694e+21,   1.03062206e+21]), array([  1.03061965e+21,   1.03059606e+21,   1.03059166e+21, ...,\n",
      "         6.15158216e+20,   6.15154201e+20,   6.14973079e+20]), array([  6.14940757e+20,   6.14921393e+20,   6.14896562e+20, ...,\n",
      "         4.72954737e+20,   4.72425565e+20,   4.72396713e+20])]\n",
      "len(f(bin_arr))= 4\n",
      "len(f(bin_arr)[0])= 20800\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 32\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 16\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 8\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 4\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 2\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(x)= 0\n",
      "len(y)= 0\n",
      "a= 64\n",
      "len(bin_arr)= 65600\n",
      "b= 41\n",
      "bin_num= 13\n",
      "f(bin_arr)= [array([  7.42259303e+22,   7.30171752e+22,   7.26586133e+22, ...,\n",
      "         1.83380933e+21,   1.83375679e+21,   1.83333765e+21]), array([  1.83326975e+21,   1.83325930e+21,   1.83313154e+21, ...,\n",
      "         1.03064421e+21,   1.03062694e+21,   1.03062206e+21]), array([  1.03061965e+21,   1.03059606e+21,   1.03059166e+21, ...,\n",
      "         6.15158216e+20,   6.15154201e+20,   6.14973079e+20]), array([  6.14940757e+20,   6.14921393e+20,   6.14896562e+20, ...,\n",
      "         4.72954737e+20,   4.72425565e+20,   4.72396713e+20])]\n",
      "len(f(bin_arr))= 4\n",
      "len(f(bin_arr)[0])= 20800\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 32\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 16\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 8\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 4\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 2\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(x)= 50\n",
      "len(y)= 50\n",
      "a= 64\n",
      "len(bin_arr)= 65600\n",
      "b= 41\n",
      "bin_num= 13\n",
      "f(bin_arr)= [array([  7.42259303e+22,   7.30171752e+22,   7.26586133e+22, ...,\n",
      "         1.83380933e+21,   1.83375679e+21,   1.83333765e+21]), array([  1.83326975e+21,   1.83325930e+21,   1.83313154e+21, ...,\n",
      "         1.03064421e+21,   1.03062694e+21,   1.03062206e+21]), array([  1.03061965e+21,   1.03059606e+21,   1.03059166e+21, ...,\n",
      "         6.15158216e+20,   6.15154201e+20,   6.14973079e+20]), array([  6.14940757e+20,   6.14921393e+20,   6.14896562e+20, ...,\n",
      "         4.72954737e+20,   4.72425565e+20,   4.72396713e+20])]\n",
      "len(f(bin_arr))= 4\n",
      "len(f(bin_arr)[0])= 20800\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 32\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 16\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 8\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 4\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 2\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good[i]))= 1600\n",
      "len(bin_arr_i)= 1\n",
      "len(x)= 0\n",
      "len(y)= 0\n",
      "INFO: Creating spectra [pyspeckit.spectrum.classes]\n",
      "INFO: Concatenating data [pyspeckit.spectrum.classes]\n",
      "INFO: Left region selection unchanged.  xminpix, xmaxpix: 0,3327 [pyspeckit.spectrum.interactive]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using a non-integer number instead of an integer will result in an error in the future\n",
      "Mean of empty slice\n",
      "WARNING: No header given.  Creating an empty one.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data are invalid; cannot be fit.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9d1f1c3b4280>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mallspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-9d1f1c3b4280>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(map_name)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprogression_binning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_table_and_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'chemical_abundance'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-9d1f1c3b4280>\u001b[0m in \u001b[0;36mmake_table_and_plot\u001b[1;34m(files, map_name, y, x, table_content, **kwargs)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;31m#                 logNH2 = log10(round(np.median(column_dens_value[y,x]), 2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[0mlogNH2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%.3g'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                 \u001b[0mparameter_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspec_curve_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m                 \u001b[0mlogNNH3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameter_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[0mchem_abund\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogNNH3\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlogNH2\u001b[0m \u001b[1;31m# = log(N(NH3)/N(H2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-9d1f1c3b4280>\u001b[0m in \u001b[0;36mspec_curve_fit\u001b[1;34m(bin_num, map_name)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[1;31m# Offset velocity (you will usually use 0 instead of 8.5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;31m# Ortho fraction (leave at 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m     \u001b[0mallspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfittype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cold_ammonia'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mguesses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;31m# You can make a plot here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nestor/anaconda2/lib/python2.7/site-packages/pyspeckit-0.1.20.dev2376-py2.7.egg/pyspeckit/config.pyc\u001b[0m in \u001b[0;36mdecorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mnew_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;31m# documentation should be passed on, else sphinx doesn't work and the user can't access the docs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nestor/anaconda2/lib/python2.7/site-packages/pyspeckit-0.1.20.dev2376-py2.7.egg/pyspeckit/spectrum/fitters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, interactive, usemoments, clear_all_connections, debug, guesses, parinfo, save, annotate, show_components, use_lmfit, verbose, clear, reset_selection, fit_plotted_area, use_window_limits, vheight, exclude, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m                 self.multifit(show_components=show_components, verbose=verbose,\n\u001b[0;32m    311\u001b[0m                               \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_lmfit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_lmfit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                               guesses=guesses, annotate=annotate, **kwargs)\n\u001b[0m\u001b[0;32m    313\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Guess and parinfo were somehow invalid.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nestor/anaconda2/lib/python2.7/site-packages/pyspeckit-0.1.20.dev2376-py2.7.egg/pyspeckit/spectrum/fitters.pyc\u001b[0m in \u001b[0;36mmultifit\u001b[1;34m(self, fittype, renormalize, annotate, show_components, verbose, color, guesses, parinfo, reset_fitspec, use_window_limits, use_lmfit, plot, **kwargs)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetfitspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_valid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data are invalid; cannot be fit.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m         \u001b[1;31m#if self.fitkwargs.has_key('negamp'): self.fitkwargs.pop('negamp') # We now do this in gaussfitter.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfittype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data are invalid; cannot be fit."
     ]
    }
   ],
   "source": [
    "# What are the variables we want set as default?\n",
    "# Taking out the user input leaves much less comparison options? what do we want to compare actually?\n",
    "# Now bin_width=500, wanted_bin=0 occure as kew words in main() and in binning() function. Is this OK?\n",
    "# Do we want to have global variable declarations in the header?\n",
    "\n",
    "import pyspeckit as psk\n",
    "from spectral_cube import SpectralCube\n",
    "import astropy.units as u\n",
    "\n",
    "import GAS\n",
    "from spectral_cube import SpectralCube\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as nd\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "import pyspeckit as psk\n",
    "from pyspeckit.spectrum.models import ammonia\n",
    "from pyspeckit.spectrum.models import ammonia_constants, ammonia, ammonia_hf\n",
    "from pyspeckit.spectrum.models.ammonia_constants import freq_dict\n",
    "from pyspeckit.spectrum.units import SpectroscopicAxis, SpectroscopicAxes\n",
    "\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "vlsr = fits.getdata('NGC1333_Vlsr_v1.fits')\n",
    "files =['NGC1333_NH3_11_DR1.fits', 'NGC1333_NH3_22_DR1.fits', 'NGC1333_NH3_33_DR1.fits', \n",
    "       'NGC1333_C2S_DR1.fits',\n",
    "       'NGC1333_HC5N_DR1.fits',\n",
    "        'NGC1333_HC7N_21_20_DR1.fits', 'NGC1333_HC7N_22_21_DR1.fits']\n",
    "\n",
    "\n",
    "# lines_margins = {files[0]: [[-1.5, 3.],[6.25, 11.],[18.5,22.5], [-8.5,-4.5], [-21., -16.5]], files[1]: [[-2., 3.], [-17., -13.5], [15.5, 19.]],\n",
    "#                  files[2]: [[-4.25, 4]], files[3]: [[-1.5, 3.]], files[4]: [[-2, 4.]], files[5]: [[-1.5, 3.]],\n",
    "#                     files[6]: [[-1.5, 3.]]}\n",
    "# noise_margins = {files[0]: [12., 17.], files[1]: [5., 12.5], files[2]: [-12, -10], files[3]: [-12, -10], files[4]: [10., 27.5], files[5]: [5., 15.],\n",
    "#                     files[6]: [5., 15.]}\n",
    "\n",
    "# bin_width = 500\n",
    "# this_bin = 69\n",
    "# bin_num = 50\n",
    "map_temp = 'NGC1333_Temperature.fits'\n",
    "map_name = 'NGC1333_DustColumn.fits'\n",
    "# map_binning = 'OrionA_NH3_11_base_DR1_mom0.fits'\n",
    "\n",
    "def main(map_name):   \n",
    "    # This is the main routine.\n",
    "    Tmax = fits.getdata(map_name)\n",
    "    bin_arr = np.sort(Tmax[np.isfinite(Tmax)])[::-1]\n",
    "    max_len = len(bin_arr)\n",
    "\n",
    "    y, x, med, bin_num = progression_binning(max_len, map_name)    \n",
    "    t, table_names = make_table_and_plot(files, map_name, y, x, table_content = 'chemical_abundance')\n",
    "    t\n",
    "    \n",
    "#     plot_spectra(this_bin, bin_width, map_name)\n",
    "#     spec_curve_fit(this_bin, map_name)\n",
    "#     t, table_names = make_table(files, this_bin, bin_width, y, x)\n",
    "#     plot_table(files, this_bin, bin_width, y, x)\n",
    "    \n",
    "\n",
    "\n",
    "def plot_spectra(map_name):\n",
    "    # line belows causes a loop of plots, their number=this_bin. If you want just a single plot, comment the line out\n",
    "    Tmax = fits.getdata(map_name)\n",
    "    bin_arr = np.sort(Tmax[np.isfinite(Tmax)])[::-1]\n",
    "    max_len = len(bin_arr)\n",
    "    \n",
    "    for bin_iteration in range(max_len):\n",
    "        loop_count = 0\n",
    "        fig = plt.figure(figsize=(14,10))\n",
    "        # for plotting plots in a single figure put plt.figure before all the .plot commands\n",
    "        # otherwise you will get the plots in a different figures\n",
    "\n",
    "        y, x, med, bin_num = progression_binning(map_name, bin_num)\n",
    "        # line below rounds med to 3 significant figures, means: 1.23456E+22 -> 1.23E+22\n",
    "        med_rounded = float('%.3g' % med)\n",
    "\n",
    "        for file_name in files:                        \n",
    "            sp_av, cube = averaging(file_name, y, x)\n",
    "            thiscube_spectrum_dv, cube, offset_velocity, sp_av = averaging_over_dopplervel(file_name, y, x)\n",
    "            #Change to velocity axis and such here as well.  Then average all spectra with that bin label.\n",
    "            ax = fig.add_subplot(len(files),1,loop_count+1)\n",
    "            plt.plot(offset_velocity,thiscube_spectrum_dv, drawstyle='steps')\n",
    "            plt.yticks(np.arange(min(thiscube_spectrum_dv), max(thiscube_spectrum_dv), (max(thiscube_spectrum_dv)-min(thiscube_spectrum_dv))/3)) \n",
    "            plt.xticks(np.arange(-30, 30, 5))\n",
    "            ax.tick_params(axis='x', labelsize=22)\n",
    "            ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "            # the two line below make the x-axis to be labelled with number values only for the very bottom spectrum.\n",
    "            # It is a way to save space and not get overwhelmed with number on the plot.\n",
    "            if file_name != files[-1]:\n",
    "                plt.setp(ax.get_xticklabels(), visible=False)\n",
    "\n",
    "            file_name = file_name.strip('L1455_').strip('_all.fits').strip('NGC1333').strip('_DR1_all.fits').strip('OrionA_').strip('_base_DR1.fits')\n",
    "            plt.legend([file_name], bbox_to_anchor=(1.01, 1.15), prop={'size':20})\n",
    "\n",
    "            loop_count += 1        \n",
    "\n",
    "        fig.suptitle(\"map=%r: Averaged spectrum from \\n $\\overline{T}_{antena} = %rK$, progressive bin size\"\n",
    "                     %(map_name, med_rounded), fontsize=20)\n",
    "        plt.ylabel(r'$T_{antena} (K)$', fontsize = 24)\n",
    "        plt.xlabel(r'$v_{\\mathrm{LSR}}\\ (\\mathrm{km} \\cdot \\mathrm{s}^{-1})$', fontsize = 24)\n",
    "        # I use .pdf for savefig through out the code, because it gives more than suficient resolution\n",
    "        plt.savefig(\"map=%r:BinsAveraging_progressive_bin_size.pdf\" %(map_name))\n",
    "        plt.show()\n",
    "        if bin_iteration == bin_num:\n",
    "            break\n",
    "\n",
    "      \n",
    "def binning(bin_width, this_bin, map_name):\n",
    "    \"\"\"A function creating brightness bins of pixels, and eventualy a map, in the given spectral cube\"\"\"\n",
    "#     cube = SpectralCube.read(map_name)\n",
    "#     cube = cube.with_spectral_unit(u.km/u.s,velocity_convention='radio')\n",
    "#     Tmax = cube.apply_numpy_function(np.nanmax,axis=0) # array of the maximum values in the spectra of each pixel\n",
    "#     baddata = nd.morphology.binary_dilation(np.isnan(Tmax),np.ones((25,25)))\n",
    "#     Tmax[baddata]=0.0\n",
    "#     Tmax[np.isfinite(Tmax)]\n",
    "    \n",
    "    Tmax = fits.getdata(map_name)\n",
    "    bin_arr = np.sort(Tmax[np.isfinite(Tmax)])\n",
    "    bin_arr2 = bin_arr[:: - bin_width] # this creates an array of the bin margins, in which every bin has a width of \"bin_width\"  \n",
    "    bins = np.digitize(Tmax,bin_arr2)\n",
    "    bins = [x-1 for x in bins] # this and the following line correct the fact that there is otherwise\n",
    "    bins = np.array(bins) # only one pixel in the bin = 0\n",
    "    y, x = np.where(bins==this_bin)\n",
    "    med = round(np.median(Tmax[y,x]), 2)\n",
    "    return y, x, med\n",
    "\n",
    "def progression_binning(bin_iteration, map_name):\n",
    "    \"\"\"Analogous to the 'binning'-function, except for the bin-width changing progressively with the pixel-numbwer.\n",
    "    It starts with 100pixels/bin for the brightest/densest regions and goes up to 1000 for the faintest.\"\"\"\n",
    "#     cube = SpectralCube.read(map_name)\n",
    "#     cube = cube.with_spectral_unit(u.km/u.s,velocity_convention='radio')\n",
    "#     Tmax = cube.apply_numpy_function(np.nanmax,axis=0) # array of the maximum values in the spectra of each pixel\n",
    "#     baddata = nd.morphology.binary_dilation(np.isnan(Tmax),np.ones((25,25)))\n",
    "#     Tmax[baddata]=0.0\n",
    "#     Tmax[np.isfinite(Tmax)]\n",
    "    \n",
    "    Tmax = fits.getdata(map_name)\n",
    "#     bin_arr = np.sort(Tmax[np.isfinite(Tmax)])\n",
    "    bin_arr = np.sort(Tmax[np.isfinite(Tmax)])[::-1]\n",
    "     \n",
    "    # n is the number of sub arrays bin_arr is being separated to\n",
    "    # I set as default n=4, since only 1/4 of all the pixels carry data good enough for analysis\n",
    "    \n",
    "    # In the 2 lines below we shorten bin_arr, so the number of its elements is a multiple of 1000\n",
    "    a = len(bin_arr)%1600\n",
    "    print 'a=', a\n",
    "    bin_arr = bin_arr[:-a]\n",
    "    print 'len(bin_arr)=', len(bin_arr)\n",
    "    \n",
    "    # next we want to tak the first 1/3 of bin_arr, that is also still a multiple of 1000\n",
    "    # I choose the first 1/3, because this is where approximately the good pixel data is located\n",
    "    # anything further can not be analysed properly\n",
    "    b = len(bin_arr)/1600\n",
    "    print 'b=', b\n",
    "    bin_num = b/3\n",
    "    print 'bin_num=', bin_num\n",
    "    # the line below connects the elements of bin_arr into sub arrays, that are part of a larger array f(A).\n",
    "    # n gives the length of the sub_arrays\n",
    "    # Example: if bin_arr = [1,2,3,4,5,6] and n=2 => f(A)=[[1,2], [3,4], [5,6]]\n",
    "    f = lambda bin_arr, l=(bin_num*1600): [bin_arr[i:i+l] for i in range(0, len(bin_arr), l)]\n",
    "    print 'f(bin_arr)=', f(bin_arr)\n",
    "    print 'len(f(bin_arr))=', len(f(bin_arr))\n",
    "    print 'len(f(bin_arr)[0])=', len(f(bin_arr)[0])\n",
    "    \n",
    "    # Now we have to do another iteration and divide the array again in m sub-arrays.\n",
    "    # Every sub array would be devided in bins, each bin cointaining 125*(2.0**i)pixels/bin\n",
    "    arr_good = f(bin_arr)[0]\n",
    "#     m=20\n",
    "    f = lambda arr_good, l=1600: [arr_good[i:i+l] for i in range(0, len(arr_good), l)]\n",
    "    \n",
    "    progr_bin_arr = []\n",
    "    for i in range(bin_num):\n",
    "        # the line below sets the progressive bin width: bin_wi(0)=1000, bin_wi(1)=500, bin_wi(2)=250\n",
    "        bin_wi = 50*(2.0**i)\n",
    "        print 'len(f(arr_good[i]))=', len(f(arr_good)[i])\n",
    "        bin_arr_i = f(arr_good)[i][:: bin_wi] # this creates an array of the bin margins, in which every bin has a width of \"bin_wi\"  \n",
    "        print 'len(bin_arr_i)=', len(bin_arr_i)\n",
    "        # the line below just adds bin_arr_i to progr_bin_arr\n",
    "        progr_bin_arr=numpy.concatenate((progr_bin_arr, bin_arr_i))\n",
    "    progr_bin_arr = np.sort(progr_bin_arr)[::-1]\n",
    "\n",
    "    bins = np.digitize(Tmax,progr_bin_arr)\n",
    "    bins = [x-1 for x in bins] # this and the following line correct the fact that there is otherwise\n",
    "    bins = np.array(bins) # only one pixel in the bin = 0\n",
    "    y, x = np.where(bins==bin_iteration)\n",
    "    med = round(np.median(Tmax[y,x]), 2)\n",
    "    print 'len(x)=', len(x)\n",
    "    print 'len(y)=', len(y)\n",
    "    return y, x, med, bin_num\n",
    "\n",
    "def averaging(file_name, y, x):\n",
    "    cube = SpectralCube.read(file_name)\n",
    "    cube = cube.with_spectral_unit(u.km/u.s,velocity_convention='radio')\n",
    "    sp_av = np.nanmean(cube.filled_data[:,y,x].value,axis=1)\n",
    "    return sp_av, cube\n",
    "\n",
    "def averaging_over_dopplervel(file_name, y, x):\n",
    "    cube = SpectralCube.read(file_name)\n",
    "    cube = cube.with_spectral_unit(u.km/u.s,velocity_convention='radio')\n",
    "    sp_av = np.nanmean(cube.filled_data[:,y,x].value,axis=1)\n",
    "    thiscube_spectrum_dv, offset_velocity = GAS.gasBinning.BinByMask(cube, CentroidMap = vlsr, x = x, y = y)\n",
    "    return thiscube_spectrum_dv, cube, offset_velocity, sp_av\n",
    "\n",
    "\n",
    "def make_table_and_plot(files, map_name, y, x, table_content = 'spectral_integral', **kwargs):        \n",
    "    Tmax = fits.getdata(map_name)\n",
    "    bin_arr = np.sort(Tmax[np.isfinite(Tmax)])[::-1]\n",
    "    max_len = len(bin_arr)\n",
    "    y, x, med, bin_num = progression_binning(max_len, map_name)\n",
    "    \n",
    "    \n",
    "    if table_content == 'spectral_integral':\n",
    "        table_names = ['map', 'bin width', 'bin#', 'quantity_med']\n",
    "        for f in files:\n",
    "            table_names.append(f.strip('NGC1333').strip('_DR1_all.fits'))\n",
    "            table_names.append(f.strip('NGC1333').strip('_DR1_all.fits')+'_err')\n",
    "        y_label=r'$\\int T_A \\mathrm{d}v$ along line of sight'\n",
    "            \n",
    "        arr = np.arange(len(table_names)*bin_num).reshape(bin_num, len(table_names))\n",
    "        t = Table(arr, names=table_names, meta={'name': 'table'}, dtype=['S30'] + (len(table_names)-1)*['f8']) \n",
    "\n",
    "        for bin_iteration in range(bin_num):\n",
    "            y, x, med = progression_binning(bin_width, bin_iteration, map_name)\n",
    "            row = [map_name, bin_width, bin_iteration, med]\n",
    "            for file_name in files:\n",
    "                thiscube_spectrum_dv, cube, offset_velocity, sp_av = averaging_over_dopplervel(file_name, y, x)\n",
    "                sp_integral, error_bar = spectral_integral_and_err(offset_velocity, thiscube_spectrum_dv, cube, file_name)\n",
    "                row.append(sp_integral)\n",
    "                row.append(error_bar)\n",
    "            t[bin_iteration] = row\n",
    "        \n",
    "        fig = plt.figure(figsize=(14,10))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.set_title(\"Spectral integrals, hyperfine included \\n Map=%r, progressive bin size\"%(map_name), fontsize=26)    \n",
    "        plt.xlabel(r'$\\overline{T_A}$', fontsize = 26)\n",
    "        plt.ylabel(r'$\\int T_A \\mathrm{d}v$ along line of sight', fontsize = 26)\n",
    "        ax1.set_xscale('symlog')\n",
    "        ax1.set_yscale('symlog', linthreshy=0.05)\n",
    "        ax1.grid(b=True, which='major', color='b', linestyle='--')\n",
    "        ax1.tick_params(axis='x', labelsize=22)\n",
    "        ax1.tick_params(axis='y', labelsize=22)\n",
    "        ax1.set_xlim([min(t['quantity_med']),max(t['quantity_med'])])\n",
    "        \n",
    "        transpa_factors = [[1,0.5,0.5,0.15] for i in range(len(t))]\n",
    "        # loop is there for plotting only the right columns of the table (no 'error'-columns, no 'map', ect.)\n",
    "        for name in table_names:\n",
    "            if '_err' in name:\n",
    "                continue\n",
    "            if 'map' in name or 'bin width' in name or 'bin#' in name or 'quantity_med' in name:\n",
    "                continue\n",
    "            plt.plot(t['quantity_med'], t[name], linewidth=3.0)\n",
    "            for x, y, err, transpa_factor in zip(t['quantity_med'], t[name], t[name+'_err'], transpa_factors):\n",
    "                ax1.errorbar(x, y, err, marker='o', color=transpa_factor, linestyle='-', lw=2) #lw is the line width of bar # yerr=t[column_name+'_err'], label=name, \n",
    "\n",
    "#         for file_name in files:\n",
    "#             column_name = file_name.strip('NGC1333').strip('_DR1_all.fits') \n",
    "#             ax1.errorbar(t['quantity_med'], t[column_name], yerr=t[column_name+'_err'], marker='o', linestyle='-', label=str(column_name)) \n",
    "        \n",
    "        leg = ax1.legend(prop={'size':15})\n",
    "        plt.savefig(\"Map=%r_%r_of_$NH_3$_progressive_bin_size.pdf\" %(map_name, table_content))\n",
    "        plt.show()\n",
    "        plt.close(fig)        \n",
    "    \n",
    "            \n",
    "    else:\n",
    "        if table_content == 'chemical_abundance':\n",
    "            table_names = ['map', 'bin width', 'bin#', 'log(N(H2))', 'chem. abund.', 'chem_ab_err']\n",
    "            y_label=r'chem. abund. $\\log\\left(\\frac{N(\\mathrm{NH}_3)}{N(\\mathrm{H}_2)}\\right)$'\n",
    "            arr = np.arange(len(table_names)*bin_num).reshape(bin_num, len(table_names))\n",
    "            t = Table(arr, names=table_names, meta={'name': 'table'}, dtype=['S30'] + (len(table_names)-1)*['f8'])\n",
    "            for bin_iteration in range(bin_num):\n",
    "                y, x, med, _ = progression_binning(bin_iteration, map_name)\n",
    "                # in the bottom two lines the medium values of the collumn density of this region is being obtained\n",
    "                # in is equal to log(N(H_2))\n",
    "#                 column_dens_value = fits.getdata(map_column_dens)  \n",
    "#                 logNH2 = log10(round(np.median(column_dens_value[y,x]), 2))\n",
    "                logNH2 = log10(float('%.3g' % med))\n",
    "                parameter_info, error_bars = spec_curve_fit(bin_iteration, map_name)\n",
    "                logNNH3 = parameter_info[2].value\n",
    "                chem_abund = logNNH3 - logNH2 # = log(N(NH3)/N(H2))\n",
    "                logNNH3_error_bar = error_bars[2] #needs to be corrected, see standart deviation of logarithmic calculations\n",
    "                row = [map_name, bin_width, bin_iteration, logNH2, chem_abund, logNNH3_error_bar]\n",
    "                t[bin_iteration] = row\n",
    "                \n",
    "            \n",
    "        elif table_content == 'temperature_kin':\n",
    "            table_names = ['map', 'bin width', 'bin#', 'log(N(H2))', 'Temp_kin', 'Temp_kin_err']\n",
    "            y_label = r'$T_{kin}$'\n",
    "            arr = np.arange(len(table_names)*this_bin).reshape(this_bin, len(table_names))\n",
    "            t = Table(arr, names=table_names, meta={'name': 'table'}, dtype=['S30'] + (len(table_names)-1)*['f8'])\n",
    "            for bin_num in range(this_bin):\n",
    "                y, x, med = binning(bin_width, bin_num)\n",
    "                # in the bottom two lines the medium values of the collumn density of this region is being obtained\n",
    "                # in is equal to log(N(H_2))\n",
    "#                 column_dens_value = fits.getdata(map_column_dens)  \n",
    "#                 logNH2 = log10(round(np.median(column_dens_value[y,x]), 2))\n",
    "                logNH2 = log10(float('%.3g' % med))\n",
    "                parameter_info, error_bars = spec_curve_fit(bin_num)\n",
    "                Temp_kin = parameter_info[0].value\n",
    "                Temp_kin_error_bar = error_bars[0]\n",
    "                row = [map_name, bin_width, bin_num, logNH2, Temp_kin, Temp_kin_error_bar]\n",
    "                t[bin_num] = row\n",
    "                \n",
    "        \n",
    "        elif table_content == 'line_width':\n",
    "            table_names = ['map', 'bin width', 'bin#', 'log(N(H2))', 'line_width', 'line_width_err']\n",
    "            y_label = r'line width $\\sigma$'\n",
    "            arr = np.arange(len(table_names)*this_bin).reshape(this_bin, len(table_names))\n",
    "            t = Table(arr, names=table_names, meta={'name': 'table'}, dtype=['S30'] + (len(table_names)-1)*['f8'])\n",
    "            for bin_num in range(this_bin):\n",
    "                y, x, med = binning(bin_width, bin_num, map_name)\n",
    "                # in the bottom two lines the medium values of the collumn density of this region is being obtained\n",
    "                # in is equal to log(N(H_2))\n",
    "#                 column_dens_value = fits.getdata(map_column_dens)  \n",
    "#                 logNH2 = log10(round(np.median(column_dens_value[y,x]), 2))\n",
    "                logNH2 = log10(float('%.3g' % med))\n",
    "                parameter_info, error_bars = spec_curve_fit(bin_num, map_name)\n",
    "                line_width = parameter_info[3].value\n",
    "                line_width_error_bar = error_bars[3] #needs to be corrected, see standart deviation of logarithmic calculations\n",
    "                row = [map_name, bin_width, bin_num, logNH2, line_width, line_width_error_bar]\n",
    "                t[bin_num] = row\n",
    "                \n",
    "#     t.write('filename.txt', format='latex') # - COOL!!!\n",
    "#     t.write('NGC1333_bin_width=%r_MaxBin#=%r_no_header.txt' %(bin_width, this_bin), format='ascii.no_header')\n",
    "#     t.write('OrionA:Table_spec_integrals_corrected_bin_width=%r_MaxBin#=%r_HYPERFINE.txt' %(bin_width, this_bin), format='ascii.fixed_width')\n",
    "    \n",
    "    if table_content != 'spectral_integral':\n",
    "        fig = plt.figure(figsize=(14,10))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.set_title(\"Map=%r: \\n %r of $\\mathrm{NH}_3$. \\n Progressive bin size: 32*50px/bin, 16*100, 8*200, 4*400, 2*800, rest*1600 \"%(map_name, table_content), fontsize=24) #     \n",
    "        plt.xlabel(r'$\\log\\left(N(\\mathrm{H}_2)\\right)$ along line of sight', fontsize = 28) # don't forget the r infront of '...' for latex formula\n",
    "        plt.ylabel(y_label, fontsize = 28)\n",
    "        ax1.tick_params(axis='x', labelsize=20)\n",
    "        ax1.tick_params(axis='y', labelsize=20)\n",
    "        # the line below sets the y-range to be 5% above the max-value and 5% below the min-value\n",
    "        ax1.set_ylim([np.amin(t[table_names[-2]]) - 0.05*np.absolute(amin(t[table_names[-2]])), np.amax(t[table_names[-2]]) + 0.05*np.absolute(amax(t[table_names[-2]]))])\n",
    "\n",
    "        transpa_factors = [[1,0,0,0.15] for i in range(len(t))]\n",
    "        plt.plot(t[table_names[-3]], t[table_names[-2]], linewidth=3.0)\n",
    "        for x, y, err, transpa_factor in zip(t[table_names[-3]], t[table_names[-2]], t[table_names[-1]], transpa_factors):\n",
    "            ax1.errorbar(x, y, err, marker='o', color=transpa_factor, linestyle='-', label=table_names[-2], lw=2) #lw is the line width of bar # yerr=t[column_name+'_err'],\n",
    "\n",
    "    #             leg = ax1.legend(prop={'size':10})\n",
    "        plt.savefig(\"Prog_bin_50*2^i__Map=%r_%r_of_$NH_3$_bins#=%r_bin_width%r.pdf\" %(map_name, table_content, bin_width, this_bin))\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "    \n",
    "    return t, table_names\n",
    "    \n",
    "    \n",
    "def spectral_integral_and_err(offset_velocity, thiscube_spectrum_dv, cube, file_name):\n",
    "    # first, calculating the integral\n",
    "    lines_margins = {'NH3_11': [[-1.5, 1.5],[6.75, 8.5],[18.75,20.], [-8.5,-7.], [-20.5, -19.25]], 'NH3_22': [[-1.5, 1.5], [-17.5, -15.5], [15., 17.]],\n",
    "                 'NH3_33': [[-1.5, 1.5]], 'C2S': [[-1.5, 1.5]], 'HC5N': [[-1.5, 1.5]], 'HC7N_21_20': [[-1.5, 1.5]],\n",
    "                    'HC7N_22_21': [[-1.5, 3.]]}\n",
    "    noise_margins = {'NH3_11': [12., 17.], 'NH3_22': [5., 12.5], 'NH3_33': [-12, -10], 'C2S': [-12, -10], 'HC5N': [10., 27.5], 'HC7N_21_20': [5., 15.],\n",
    "                    'HC7N_22_21': [5., 15.]}\n",
    "    \n",
    "    if 'NH3_11' in file_name:\n",
    "        file_name = 'NH3_11'\n",
    "    elif 'NH3_22' in file_name:\n",
    "        file_name = 'NH3_22'\n",
    "    elif 'NH3_33' in file_name:\n",
    "        file_name = 'NH3_33'\n",
    "    elif 'C2S' in file_name:\n",
    "        file_name = 'C2S'\n",
    "    elif 'HC5N' in file_name:\n",
    "        file_name = 'HC5N'\n",
    "    elif 'HC7N_21_20' in file_name:\n",
    "        file_name = 'HC7N_21_20'\n",
    "    elif 'HC7N_22_21' in file_name:\n",
    "        file_name = 'HC7N_22_21'\n",
    "        \n",
    "        \n",
    "    # in line below calculating the spectral-bin-width, assuming that all spectral-bins have the same width\n",
    "    spec_bin_w = (cube.spectral_axis[1] - cube.spectral_axis[2])\n",
    "    sp_integral = 0\n",
    "\n",
    "    for line_interval in lines_margins[file_name]:\n",
    "        ind_line = (line_interval[0] < offset_velocity) & (offset_velocity < line_interval[1])\n",
    "        sp_integral += np.nansum(thiscube_spectrum_dv[ind_line]) * spec_bin_w\n",
    "\n",
    "# below calculating the error, based on the standard deviation of the signal noise\n",
    "        ind_offset = (noise_margins[file_name][0] < offset_velocity) & (offset_velocity < noise_margins[file_name][1])\n",
    "        std_noise = np.nanstd(thiscube_spectrum_dv[ind_offset])\n",
    "        # Nchan should be the # of channels, that contribute to the integral (= # of data points in spectral line)\n",
    "        Nchan = len(thiscube_spectrum_dv[ind_line])\n",
    "        error = std_noise*np.sqrt(Nchan)\n",
    "     \n",
    "    return sp_integral.value, error\n",
    "    \n",
    "def spec_curve_fit(bin_num, map_name):\n",
    "    # following loop has not good style. One should build in some break statements or error messages\n",
    "    # if files repeatedly appear in loop.\n",
    "    \n",
    "    Tmax = fits.getdata(map_name)\n",
    "    bin_arr = np.sort(Tmax[np.isfinite(Tmax)])[::-1]\n",
    "    max_len = len(bin_arr)\n",
    "    \n",
    "    for one_file in files:\n",
    "        if 'NH3_11' in one_file:\n",
    "            file_name_NH3_11 = one_file\n",
    "        if 'NH3_22' in one_file:\n",
    "            file_name_NH3_22 = one_file\n",
    "        if 'NH3_33' in one_file:\n",
    "            file_name_NH3_33 = one_file\n",
    "        \n",
    "    y, x, med, _ = progression_binning(max_len, map_name)\n",
    "\n",
    "    s11, _, offset_velocity11, sp_av11 = averaging_over_dopplervel(file_name_NH3_11, y, x)\n",
    "    s22, _, offset_velocity22, sp_av22 = averaging_over_dopplervel(file_name_NH3_22, y, x)\n",
    "    s33, _, offset_velocity33, sp_av33 = averaging_over_dopplervel(file_name_NH3_33, y, x)\n",
    "    \n",
    "    xarr11 = SpectroscopicAxis(offset_velocity11*u.km/u.s, velocity_convention='radio',\n",
    "                           refX=freq_dict['oneone']).as_unit(u.GHz)\n",
    "    xarr22 = SpectroscopicAxis(offset_velocity22*u.km/u.s, velocity_convention='radio',\n",
    "                           refX=freq_dict['twotwo']).as_unit(u.GHz)\n",
    "    xarr33 = SpectroscopicAxis(offset_velocity33*u.km/u.s, velocity_convention='radio',\n",
    "                           refX=freq_dict['threethree']).as_unit(u.GHz)\n",
    "        \n",
    "    sp11 = psk.Spectrum(data=s11, xarr=xarr11, xarrkwargs={'unit':'km/s'},unit='K')\n",
    "    sp22 = psk.Spectrum(data=s22, xarr=xarr22, xarrkwargs={'unit':'km/s'},unit='K')\n",
    "    sp33 = psk.Spectrum(data=s33, xarr=xarr33, xarrkwargs={'unit':'km/s'},unit='K')\n",
    "    \n",
    "    # This joins all the spectra together into one object.\n",
    "    allspec = psk.Spectra([sp11,sp22,sp33])\n",
    "    allspec.xarr.as_unit('Hz',velocity_convention='radio')\n",
    "    # This add the cold_ammonia model to the list of things we can use for fitting\n",
    "    allspec.specfit.Registry.add_fitter('cold_ammonia',ammonia.cold_ammonia_model(),6)\n",
    "    # This does the fit.  The values of the guess are \n",
    "    # Kinetic Temperature (usually about 15 to 25 K)\n",
    "    # Excitation Temperature (between 2.73 K and the excitation temperature)\n",
    "    # Log Column Density of ammonia\n",
    "    # Line width (~1 km/s)\n",
    "    # Offset velocity (you will usually use 0 instead of 8.5)\n",
    "    # Ortho fraction (leave at 0)\n",
    "    allspec.specfit(fittype='cold_ammonia',guesses=[23,5,13.1,1,0,0])\n",
    "    \n",
    "    # You can make a plot here.\n",
    "    fig = plt.figure()\n",
    "    allspec.plotter()\n",
    "    allspec.specfit.plot_fit(lw=1, components=True)\n",
    "    plt.xlim((23.692,23.697))\n",
    "#     plt.xlim((23.72,23.725))\n",
    "#     plt.xlim((23.8692, 23.8708))\n",
    "#     plt.savefig(\"OrionA:pyspeckit_fit_bin_width=%rthis_bin=%r.ps\" %(bin_width, this_bin))\n",
    "#     plt.savefig(\"Map=%r:bin_num=%r_pyspeckit_fit_NH3_11TEST.eps\"%(map_name, bin_num))\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # returns the values of the fitted parameters: T_K, T_ex, N, sigma, v, F_0\n",
    "    return allspec.specfit.parinfo, allspec.specfit.parinfo.errors\n",
    "    \n",
    "main(map_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [1, 0, 0, 0.2]\n",
      "20 [1, 0, 0, 0.2]\n",
      "30 [1, 0, 0, 0.2]\n"
     ]
    }
   ],
   "source": [
    "transpa_factors = [[1,0,0,0.2] for i in range(3)]\n",
    "for x, factor in zip([10,20,30], transpa_factors):\n",
    "    print x, factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "table_names = ['map', 'bin width', 'bin#', 'quantity_med', 'bla' ,'1', '2', '3', '3_err']\n",
    "for name in table_names:\n",
    "    if '_err' in name:\n",
    "        continue\n",
    "    if 'map' in name or 'bin width' in name or 'bin#' in name or 'quantity_med' in name:\n",
    "        continue\n",
    "    print name\n",
    "#     if not '_err' in name and not name in ('map' and 'bin_width' and 'bin#' and 'quantity_med'):\n",
    "#         print name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65], [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98], [99]]\n"
     ]
    }
   ],
   "source": [
    "A = [i for i in range(100)]\n",
    "n = len(A)/3\n",
    "f = lambda A, n= len(A)/3: [A[i:i+n] for i in range(0, len(A), n)]\n",
    "print f(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial bin_arr2= [499, 484, 469, 454, 439, 424, 409, 394, 379, 364, 349, 334, 319, 304, 289, 274, 259, 244, 229, 214, 199, 184, 169, 154, 139, 124, 109, 94, 79, 64, 49, 34, 19, 4]\n",
      "len(f(bin_arr))= 4\n",
      "f(bin_arr)[4]= [375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499]\n",
      "bin_arr_i [124, 109, 94, 79, 64, 49, 34, 19, 4]\n",
      "bin_arr_i [249, 219, 189, 159, 129]\n",
      "bin_arr_i [374, 329, 284]\n",
      "bin_arr_i [499, 439, 379]\n",
      "progr_bin_arr= [124, 109, 94, 79, 64, 49, 34, 19, 4, 249, 219, 189, 159, 129, 374, 329, 284, 499, 439, 379]\n"
     ]
    }
   ],
   "source": [
    "bin_arr = range(500)\n",
    "print 'initial bin_arr2=', bin_arr[:: - 15]\n",
    "\n",
    "n=4\n",
    "f = lambda bin_arr, l=len(bin_arr)/n: [bin_arr[i:i+l] for i in range(0, len(bin_arr), l)] \n",
    "\n",
    "print 'len(f(bin_arr))=', len(f(bin_arr))\n",
    "print 'f(bin_arr)[4]=', f(bin_arr)[3]\n",
    "\n",
    "progr_bin_arr = []\n",
    "for i in range(n):\n",
    "    bin_wi = 15*(i+1)\n",
    "    bin_arr_i = ('bin_arr_' + str(i))\n",
    "    bin_arr_i = f(bin_arr)[i][:: - bin_wi]\n",
    "    print 'bin_arr_i', bin_arr_i\n",
    "    progr_bin_arr += bin_arr_i\n",
    "\n",
    "print 'progr_bin_arr=', progr_bin_arr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= 345\n",
      "len(bin_arr)= 65000\n",
      "b= 65\n",
      "c= 21\n",
      "len(f(bin_arr))= 4\n",
      "len(f(bin_arr)[0])= 21000\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 125\n",
      "len(bin_arr_i)= 8\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 250\n",
      "len(bin_arr_i)= 4\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 500\n",
      "len(bin_arr_i)= 2\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 1000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 2000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 4000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 8000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 16000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 32000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 64000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 128000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 256000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 512000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 1024000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 2048000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 4096000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 8192000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 16384000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 32768000\n",
      "len(bin_arr_i)= 1\n",
      "len(f(arr_good)[i])= 1000\n",
      "bin_wi = 65536000\n",
      "len(bin_arr_i)= 1\n"
     ]
    }
   ],
   "source": [
    "bin_arr = range(65345)\n",
    "a = len(bin_arr)%1000\n",
    "print 'a=', a\n",
    "bin_arr = bin_arr[:-a]\n",
    "print 'len(bin_arr)=', len(bin_arr)\n",
    "\n",
    "# next we want to tak the first 1/3 of bin_arr, that is also still a multiple of 1000\n",
    "# I choose the first 1/3, because this is where approximately the good pixel data is located\n",
    "# anything further can not be analysed properly\n",
    "b = len(bin_arr)/1000\n",
    "print 'b=', b\n",
    "c = b/3\n",
    "print 'c=', c\n",
    "# the line below connects the elements of bin_arr into sub arrays, that are part of a larger array f(A).\n",
    "# n gives the length of the sub_arrays\n",
    "# Example: if bin_arr = [1,2,3,4,5,6] and n=2 => f(A)=[[1,2], [3,4], [5,6]]\n",
    "f = lambda bin_arr, l=(c*1000): [bin_arr[i:i+l] for i in range(0, len(bin_arr), l)]\n",
    "# print 'f(bin_arr)=', f(bin_arr)\n",
    "print 'len(f(bin_arr))=', len(f(bin_arr))\n",
    "print 'len(f(bin_arr)[0])=', len(f(bin_arr)[0])\n",
    "\n",
    "# Now we have to do another iteration and divide the array again in m sub-arrays.\n",
    "# Every sub array would be devided in bins, each bin cointaining 125*(2.0**i)pixels/bin\n",
    "arr_good = f(bin_arr)[0]\n",
    "# m=20\n",
    "f = lambda arr_good, l=1000: [arr_good[i:i+l] for i in range(0, len(arr_good), l)]\n",
    "\n",
    "progr_bin_arr = []\n",
    "for i in range(m):\n",
    "    # the line below sets the progressive bin width: bin_wi(0)=1000, bin_wi(1)=500, bin_wi(2)=250\n",
    "    bin_wi = 125*(2**i)\n",
    "    print 'len(f(arr_good)[i])=', len(f(arr_good)[i])\n",
    "    print 'bin_wi =', bin_wi\n",
    "    bin_arr_i = f(arr_good)[i][:: bin_wi] # this creates an array of the bin margins, in which every bin has a width of \"bin_wi\"  \n",
    "    print 'len(bin_arr_i)=', len(bin_arr_i)\n",
    "    # the line below just adds bin_arr_i to progr_bin_arr\n",
    "    progr_bin_arr=numpy.concatenate((progr_bin_arr, bin_arr_i))\n",
    "progr_bin_arr = np.sort(progr_bin_arr)[::-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
